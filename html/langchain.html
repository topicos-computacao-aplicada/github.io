<!DOCTYPE html>
<html lang="pt-BR">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Framework LangChain - T√≥picos em Computa√ß√£o Aplicada</title>
<link rel="stylesheet" href="https://unpkg.com/reveal.js/dist/reveal.css">
<link rel="stylesheet" href="https://unpkg.com/reveal.js/dist/theme/white.css">
<script src="https://unpkg.com/reveal.js/dist/reveal.js"></script>
<style>
.reveal pre code {
  font-size: 0.9em;
  line-height: 1.4em;
}
.reveal section img {
  border-radius: 10px;
  box-shadow: 0 0 10px rgba(0,0,0,0.3);
}
</style>
</head>
<body>
<div class="reveal">
<div class="slides">

<section>
  <h2>üß† Framework LangChain</h2>
  <h4>T√≥picos em Computa√ß√£o Aplicada</h4>
  <p>Prof. Armando Soares Sousa - UFPI</p>
</section>

<section>
  <h3>O que √© o LangChain?</h3>
  <ul>
    <li>Framework open-source para construir aplica√ß√µes com Modelos de Linguagem (LLMs).</li>
    <li>Facilita integra√ß√£o entre modelos, fontes de dados e l√≥gica de aplica√ß√£o.</li>
    <li>Permite criar pipelines complexos de IA generativa, como chatbots, agentes e sistemas RAG.</li>
  </ul>
</section>

<section>
  <h3>Arquitetura Geral</h3>
  <img src="https://docs.langchain.com/img/architecture.svg" alt="LangChain Architecture" width="80%">
  <p>O LangChain atua como uma camada de orquestra√ß√£o entre o LLM e o mundo real (dados, APIs, mem√≥ria e contexto).</p>
</section>

<section>
  <h3>Principais Conceitos</h3>
  <ul>
    <li><b>PromptTemplates:</b> moldes de prompts din√¢micos com vari√°veis.</li>
    <li><b>LLMs:</b> interfaces unificadas para modelos como GPT, Mistral, Gemma, etc.</li>
    <li><b>Chains:</b> sequ√™ncia de componentes conectados que processam entrada e sa√≠da.</li>
    <li><b>Memory:</b> guarda o hist√≥rico de intera√ß√µes (essencial para chatbots).</li>
    <li><b>Tools e Agents:</b> permitem que o LLM use ferramentas externas (ex: calculadoras, APIs, bancos de dados).</li>
  </ul>
</section>

<section>
  <h3>Exemplo 1 ‚Äî Criando um PromptTemplate</h3>
  <pre><code class="python">
from langchain.prompts import PromptTemplate

template = "Traduza o seguinte texto para portugu√™s: {texto}"
prompt = PromptTemplate.from_template(template)

print(prompt.format(texto="Hello, how are you?"))
  </code></pre>
  <p>‚û°Ô∏è Permite gerar prompts din√¢micos e reutiliz√°veis.</p>
</section>

<section>
  <h3>Exemplo 2 ‚Äî Usando um LLM</h3>
  <pre><code class="python">
from langchain.llms import OpenAI

llm = OpenAI(model="gpt-3.5-turbo", temperature=0.7)
resposta = llm("Explique o que √© aprendizado supervisionado.")
print(resposta)
  </code></pre>
  <p>LangChain padroniza o acesso a diferentes provedores de LLMs (OpenAI, Hugging Face, Ollama, etc).</p>
</section>

<section>
  <h3>Exemplo 3 ‚Äî Criando uma Chain</h3>
  <pre><code class="python">
from langchain import LLMChain
from langchain.prompts import PromptTemplate
from langchain.llms import OpenAI

template = "Explique o conceito de {conceito} de forma simples."
prompt = PromptTemplate.from_template(template)
llm = OpenAI(model="gpt-3.5-turbo")

chain = LLMChain(llm=llm, prompt=prompt)
print(chain.run(conceito="Intelig√™ncia Artificial"))
  </code></pre>
</section>

<section>
  <h3>Memory e Conversas Contextuais</h3>
  <pre><code class="python">
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain.llms import OpenAI

llm = OpenAI(temperature=0.6)
memory = ConversationBufferMemory()
conversation = ConversationChain(llm=llm, memory=memory)

conversation.run("Ol√°! Quem √© voc√™?")
conversation.run("E qual √© o seu papel na IA?")
  </code></pre>
  <p>‚û°Ô∏è O hist√≥rico da conversa √© armazenado e usado nas pr√≥ximas respostas.</p>
</section>

<section>
  <h3>Agents e Tools</h3>
  <ul>
    <li><b>Agents:</b> LLMs que tomam decis√µes sobre quais ferramentas usar e quando.</li>
    <li><b>Tools:</b> Fun√ß√µes externas (API, banco de dados, busca web, etc.).</li>
  </ul>
  <pre><code class="python">
from langchain.agents import load_tools, initialize_agent

tools = load_tools(["serpapi", "llm-math"], llm=llm)
agent = initialize_agent(tools, llm, agent_type="zero-shot-react-description")

agent.run("Quantos anos faltam para 2050?")
  </code></pre>
</section>

<section>
  <h3>Retrieval-Augmented Generation (RAG)</h3>
  <p>LangChain √© amplamente usado para implementar RAG ‚Äî busca de informa√ß√µes + gera√ß√£o de texto.</p>
  <ul>
    <li>Integra√ß√£o com bancos vetoriais (Chroma, FAISS, Milvus, etc.).</li>
    <li>Permite consultar PDFs, sites e bases de dados antes de gerar a resposta.</li>
  </ul>
  <pre><code class="python">
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.chains import RetrievalQA

db = Chroma(persist_directory="dados", embedding_function=OpenAIEmbeddings())
retriever = db.as_retriever()
qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

qa.run("Qual √© o objetivo do projeto SoberanIA?")
  </code></pre>
</section>

<section>
  <h3>Casos de Uso Reais</h3>
  <ul>
    <li>Chatbots com mem√≥ria e contexto.</li>
    <li>Assistentes de c√≥digo (CodeGPT, GitHub Copilot).</li>
    <li>Aplica√ß√µes de perguntas e respostas sobre documentos (RAG Apps).</li>
    <li>Agentes aut√¥nomos (AutoGPT, BabyAGI).</li>
  </ul>
</section>

<section>
  <h3>Integra√ß√µes Populares</h3>
  <ul>
    <li>Modelos: OpenAI, Mistral, Hugging Face, Ollama, Gemini, Anthropic.</li>
    <li>Armazenamento Vetorial: ChromaDB, Pinecone, Weaviate, FAISS.</li>
    <li>Frameworks: FastAPI, Flask, Streamlit.</li>
    <li>Orquestra√ß√£o: LangServe, LangSmith.</li>
  </ul>
</section>

<section>
  <h3>Boas Pr√°ticas</h3>
  <ul>
    <li>Definir temperatura e top_p conforme o contexto.</li>
    <li>Proteger chaves de API em vari√°veis de ambiente.</li>
    <li>Utilizar logs e rastreamento com LangSmith.</li>
    <li>Monitorar custos e desempenho do LLM.</li>
  </ul>
</section>

<section>
  <h3>Conclus√£o</h3>
  <p>LangChain √© o principal framework para engenharia de aplica√ß√µes baseadas em LLMs.</p>
  <p>Permite compor modelos, dados e l√≥gica de forma modular e escal√°vel.</p>
  <p>Dominar LangChain √© um passo essencial para desenvolver sistemas de IA generativa modernos.</p>
</section>

<section>
  <h3>Refer√™ncias</h3>
  <ul>
    <li>LangChain Documentation ‚Äì <a href="https://python.langchain.com" target="_blank">python.langchain.com</a></li>
    <li>LangChain GitHub ‚Äì <a href="https://github.com/langchain-ai/langchain" target="_blank">github.com/langchain-ai/langchain</a></li>
    <li>LangSmith & LangServe ‚Äì <a href="https://smith.langchain.com" target="_blank">smith.langchain.com</a></li>
  </ul>
</section>

</div>
</div>
<script>
  Reveal.initialize({
    hash: true,
    slideNumber: true
  });
</script>
</body>
</html>